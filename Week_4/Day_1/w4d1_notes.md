# W4D1 notes

## This Week

Machine Learning

## Today

Dimensionality Reduction

## Lecture

- Why do we need dimensionality reduction?
  - improves performance and runtime
  - improves memory
  - Visualization
- Dimensionality Reduction
  - PCA: Principal Component Analysis
    - Unsupervised ML
    - most variability
    - Sum of square distances for Principal Component 1 (PC1) is the eigenvalue for PC1
  - LDA: Linear Discriminant Analysis
    - Supervised - most seperability - only for classification
- Variable Selection Techniques
  - Filter Methods
  - Wrapper Methods
  - Recursive Feature Elimination
        `sklearn` `rfe`